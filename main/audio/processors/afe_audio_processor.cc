#include "afe_audio_processor.h"
#include <esp_log.h>

#define PROCESSOR_RUNNING 0x01

#define TAG "AfeAudioProcessor"

AfeAudioProcessor::AfeAudioProcessor()
    : afe_data_(nullptr) {
    event_group_ = xEventGroupCreate();

    // é¢„åˆ†é…è¾“å‡ºç¼“å†²åŒºï¼Œé¿å…é¢‘ç¹é‡æ–°åˆ†é…
    output_buffer_.reserve(8192);  // é¢„åˆ†é…8KBç©ºé—´

    // æ‰“å°å†…å­˜ä¿¡æ¯
    ESP_LOGI(TAG, "AFE constructor - Free heap: %" PRIu32 " bytes", esp_get_free_heap_size());
    ESP_LOGI(TAG, "AFE constructor - Free internal heap: %" PRIu32 " bytes", esp_get_free_internal_heap_size());
}

void AfeAudioProcessor::Initialize(AudioCodec* codec, int frame_duration_ms) {
    codec_ = codec;
    frame_samples_ = frame_duration_ms * 16000 / 1000;

    // Pre-allocate output buffer capacity
    output_buffer_.reserve(frame_samples_);

    int ref_num = codec_->input_reference() ? 1 : 0;

    std::string input_format;
    for (int i = 0; i < codec_->input_channels() - ref_num; i++) {
        input_format.push_back('M');
    }
    for (int i = 0; i < ref_num; i++) {
        input_format.push_back('R');
    }

    srmodel_list_t *models = esp_srmodel_init("model");
    char* ns_model_name = esp_srmodel_filter(models, ESP_NSNET_PREFIX, NULL);
    char* vad_model_name = esp_srmodel_filter(models, ESP_VADN_PREFIX, NULL);
    
    afe_config_t* afe_config = afe_config_init(input_format.c_str(), NULL, AFE_TYPE_VC, AFE_MODE_HIGH_PERF);
    afe_config->aec_mode = AEC_MODE_VOIP_HIGH_PERF;
    afe_config->vad_mode = VAD_MODE_0;  // æ•°å€¼è¶Šå¤§è§¦å‘æ¦‚çŽ‡è¶Šé«˜
    afe_config->vad_min_noise_ms = 800;  // 800msé™éŸ³æ—¶é•¿ï¼Œé™ä½Žè¯¯è§¦å‘ï¼ˆå®˜æ–¹æŽ¨è1000msï¼‰
    
    // æ·»åŠ æ›´å¤šVADè°ƒä¼˜å‚æ•°ä»¥é™ä½Žçµæ•åº¦ï¼ˆä½¿ç”¨ESP-SRå®žé™…æ”¯æŒçš„å‚æ•°ï¼‰
    afe_config->vad_min_speech_ms = 192;  // è¯­éŸ³æ®µçš„æœ€çŸ­æŒç»­æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    afe_config->vad_delay_ms = 224;       // VADé¦–å¸§è§¦å‘åˆ°è¯­éŸ³é¦–å¸§æ•°æ®çš„å»¶è¿Ÿé‡
    
    if (vad_model_name != nullptr) {
        afe_config->vad_model_name = vad_model_name;
    }

    if (ns_model_name != nullptr) {
        afe_config->ns_init = true;
        afe_config->ns_model_name = ns_model_name;
        afe_config->afe_ns_mode = AFE_NS_MODE_NET;
    } else {
        afe_config->ns_init = false;
    }

    afe_config->afe_perferred_core = 1;
    afe_config->afe_perferred_priority = 1;
    afe_config->agc_init = false;
    afe_config->memory_alloc_mode = AFE_MEMORY_ALLOC_MORE_PSRAM;

#ifdef CONFIG_USE_DEVICE_AEC
    afe_config->aec_init = true;
    afe_config->vad_init = true;  // å¼ºåˆ¶å¯ç”¨VADä»¥æ”¯æŒSpeakingçŠ¶æ€ä¸‹çš„æ‰“æ–­æ£€æµ‹
#else
    afe_config->aec_init = false;
    afe_config->vad_init = true;
#endif

    afe_iface_ = esp_afe_handle_from_config(afe_config);
    afe_data_ = afe_iface_->create_from_config(afe_config);
    
    xTaskCreate([](void* arg) {
        auto this_ = (AfeAudioProcessor*)arg;
        this_->AudioProcessorTask();
        vTaskDelete(NULL);
    }, "audio_communication", 4096, this, 3, NULL);
}

AfeAudioProcessor::~AfeAudioProcessor() {
    if (afe_data_ != nullptr) {
        afe_iface_->destroy(afe_data_);
    }
    vEventGroupDelete(event_group_);
}

size_t AfeAudioProcessor::GetFeedSize() {
    if (afe_data_ == nullptr) {
        return 0;
    }
    return afe_iface_->get_feed_chunksize(afe_data_);
}

void AfeAudioProcessor::Feed(std::vector<int16_t>&& data) {
    if (afe_data_ == nullptr) {
        return;
    }
    afe_iface_->feed(afe_data_, data.data());
}

void AfeAudioProcessor::Start() {
    xEventGroupSetBits(event_group_, PROCESSOR_RUNNING);
}

void AfeAudioProcessor::Stop() {
    xEventGroupClearBits(event_group_, PROCESSOR_RUNNING);
    if (afe_data_ != nullptr) {
        afe_iface_->reset_buffer(afe_data_);
    }
}

bool AfeAudioProcessor::IsRunning() {
    return xEventGroupGetBits(event_group_) & PROCESSOR_RUNNING;
}

void AfeAudioProcessor::OnOutput(std::function<void(std::vector<int16_t>&& data)> callback) {
    output_callback_ = callback;
}

void AfeAudioProcessor::OnVadStateChange(std::function<void(bool speaking)> callback) {
    vad_state_change_callback_ = callback;
}

void AfeAudioProcessor::AudioProcessorTask() {
    auto fetch_size = afe_iface_->get_fetch_chunksize(afe_data_);
    auto feed_size = afe_iface_->get_feed_chunksize(afe_data_);
    ESP_LOGI(TAG, "Audio communication task started, feed size: %d fetch size: %d",
        feed_size, fetch_size);

    while (true) {
        xEventGroupWaitBits(event_group_, PROCESSOR_RUNNING, pdFALSE, pdTRUE, portMAX_DELAY);

        auto res = afe_iface_->fetch_with_delay(afe_data_, portMAX_DELAY);
        if ((xEventGroupGetBits(event_group_) & PROCESSOR_RUNNING) == 0) {
            continue;
        }
        if (res == nullptr || res->ret_value == ESP_FAIL) {
            if (res != nullptr) {
                ESP_LOGI(TAG, "Error code: %d", res->ret_value);
            }
            continue;
        }

        // VAD state change - ä¼˜åŒ–ï¼šåªåœ¨çŠ¶æ€å˜åŒ–æ—¶å¤„ç†ç¼“å­˜
        if (vad_state_change_callback_) {
            // æ·»åŠ è°ƒè¯•æ—¥å¿—æ˜¾ç¤ºVADåŽŸå§‹çŠ¶æ€
            static int vad_log_counter = 0;
            if (++vad_log_counter % 10 == 0) {  // æ¯50æ¬¡æ‰“å°ä¸€æ¬¡ï¼Œé¿å…æ—¥å¿—è¿‡å¤š
                ESP_LOGI(TAG, "VAD raw state: %d, is_speaking_: %s, cache_size: %d",
                    res->vad_state, is_speaking_ ? "true" : "false", res->vad_cache_size);
            }
    
            if (res->vad_state == VAD_SPEECH && !is_speaking_) {
                is_speaking_ = true;//æ£€æµ‹åˆ°ç”¨æˆ·è¯´è¯
                // 1. VADç®—æ³•å›ºæœ‰å»¶è¿Ÿï¼šVADæ— æ³•åœ¨é¦–å¸§ç²¾å‡†è§¦å‘ï¼Œå¯èƒ½æœ‰1-3å¸§å»¶è¿Ÿ
                // 2. é˜²è¯¯è§¦æœºåˆ¶ï¼šéœ€æŒç»­è§¦å‘æ—¶é—´è¾¾åˆ°vad_min_speech_msæ‰ä¼šæ­£å¼è§¦å‘
                if (res->vad_cache_size > 0 && output_callback_) {
                    // ðŸ›¡ï¸ å¢žå¼ºå®‰å…¨æ£€æŸ¥
                    const size_t MAX_CACHE_SIZE = 16384;  // 8KBæœ€å¤§ç¼“å­˜é™åˆ¶

                    if (res->vad_cache == nullptr) {
                        ESP_LOGE(TAG, "VAD cache pointer is null");
                    } else if (res->vad_cache_size % sizeof(int16_t) != 0) {
                        ESP_LOGE(TAG, "VAD cache size not aligned: %d", res->vad_cache_size);
                    } else if (res->vad_cache_size > MAX_CACHE_SIZE) {
                        ESP_LOGE(TAG, "VAD cache size too large: %d > %d", res->vad_cache_size, MAX_CACHE_SIZE);
                    } else {
                        // å®‰å…¨å¤„ç†VADç¼“å­˜
                        size_t cache_samples = res->vad_cache_size / sizeof(int16_t);
                        int16_t* cache_data = (int16_t*)res->vad_cache;

                        ESP_LOGI(TAG, "Processing VAD cache: %d bytes, %d samples",
                                res->vad_cache_size, (int)cache_samples);

                        try {
                            // é¢„å…ˆä¿ç•™ç©ºé—´ï¼Œé¿å…å¤šæ¬¡é‡æ–°åˆ†é…
                            size_t new_size = output_buffer_.size() + cache_samples;
                            output_buffer_.reserve(new_size);

                            // ä¼˜å…ˆå¤„ç†ç¼“å­˜æ•°æ®ï¼Œé¿å…é¦–å­—æˆªæ–­
                            output_buffer_.insert(output_buffer_.begin(), cache_data, cache_data + cache_samples);

                            ESP_LOGI(TAG, "VAD cache processed successfully, buffer size: %d",
                                    (int)output_buffer_.size());
                        } catch (const std::exception& e) {
                            ESP_LOGE(TAG, "Exception processing VAD cache: %s", e.what());
                        } catch (...) {
                            ESP_LOGE(TAG, "Unknown exception processing VAD cache");
                        }
                    }
                }

                vad_state_change_callback_(true);
            } else if (res->vad_state == VAD_SILENCE && is_speaking_) {
                is_speaking_ = false;//ðŸŽ¯ ç”¨æˆ·åœæ­¢è¯´è¯
                vad_state_change_callback_(false);
            }
        }

        if (output_callback_) {
            size_t samples = res->data_size / sizeof(int16_t);
            
            // Add data to buffer
            output_buffer_.insert(output_buffer_.end(), res->data, res->data + samples);
            
            // Output complete frames when buffer has enough data
            while (output_buffer_.size() >= frame_samples_) {
                if (output_buffer_.size() == frame_samples_) {
                    // If buffer size equals frame size, move the entire buffer
                    output_callback_(std::move(output_buffer_));
                    output_buffer_.clear();
                    output_buffer_.reserve(frame_samples_);
                } else {
                    // If buffer size exceeds frame size, copy one frame and remove it
                    output_callback_(std::vector<int16_t>(output_buffer_.begin(), output_buffer_.begin() + frame_samples_));
                    output_buffer_.erase(output_buffer_.begin(), output_buffer_.begin() + frame_samples_);
                }
            }
        }
    }
}

void AfeAudioProcessor::EnableDeviceAec(bool enable) {
    if (enable) {
#if CONFIG_USE_DEVICE_AEC
        afe_iface_->disable_vad(afe_data_);
        afe_iface_->enable_aec(afe_data_);
#else
        ESP_LOGE(TAG, "Device AEC is not supported");
#endif
    } else {
        afe_iface_->disable_aec(afe_data_);
        afe_iface_->enable_vad(afe_data_);
    }
}
